{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vikaash07/machine-learning/blob/main/brain_tumor_E0122049.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvItczkasgOX"
      },
      "source": [
        "CONNECTING DRIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcMCJlPzBC6F"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scoOZeZZ1274"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import itertools\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0at1EqS1klG"
      },
      "outputs": [],
      "source": [
        "# import handling data tools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KCAENQDH8aU"
      },
      "outputs": [],
      "source": [
        "# import Deep Learning Libs\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4Ba4Hv6HUge"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu5wGlQO2uxp"
      },
      "outputs": [],
      "source": [
        "# Generate Data paths with labels (TRAIN)\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/brain tumor data/Training'\n",
        "filepaths = []\n",
        "labels = []\n",
        "\n",
        "folds = os.listdir(train_data_dir)\n",
        "for fold in folds:\n",
        "    foldpath = os.path.join(train_data_dir, fold)\n",
        "    filelist = os.listdir(foldpath)\n",
        "    for file in filelist:\n",
        "        fpath = os.path.join(foldpath, file)\n",
        "\n",
        "        filepaths.append(fpath)\n",
        "        labels.append(fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVaGmFjy24qi"
      },
      "outputs": [],
      "source": [
        "# Concatenate Data Paths with Labels into one Dataframe\n",
        "\n",
        "FSeries = pd.Series(filepaths, name='filepaths')\n",
        "LSeries = pd.Series(labels, name='labels')\n",
        "\n",
        "train_df = pd.concat([FSeries, LSeries], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s68AXJSU3FgU"
      },
      "outputs": [],
      "source": [
        "# Generate Data paths with labels (TEST)\n",
        "\n",
        "test_data_dir = '/content/drive/MyDrive/brain tumor data/Testing'\n",
        "filepaths = []\n",
        "labels = []\n",
        "\n",
        "folds = os.listdir(test_data_dir)\n",
        "for fold in folds:\n",
        "    foldpath = os.path.join(test_data_dir, fold)\n",
        "    filelist = os.listdir(foldpath)\n",
        "    for file in filelist:\n",
        "        fpath = os.path.join(foldpath, file)\n",
        "\n",
        "        filepaths.append(fpath)\n",
        "        labels.append(fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg7oy8A13MLx"
      },
      "outputs": [],
      "source": [
        "FSeries = pd.Series(filepaths, name='filepaths')\n",
        "LSeries = pd.Series(labels, name='labels')\n",
        "\n",
        "ts_df = pd.concat([FSeries, LSeries], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecF2dMyU3Q5x"
      },
      "outputs": [],
      "source": [
        "FSeries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RqsH5j03SWB"
      },
      "outputs": [],
      "source": [
        "LSeries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRAndFkR3VQE"
      },
      "outputs": [],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPouhrEI3Ylc"
      },
      "outputs": [],
      "source": [
        "# valid and test dataframe\n",
        "valid_df, test_df = train_test_split(ts_df,  train_size= 0.5, shuffle= True, random_state= 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NXK_2CJ3aob"
      },
      "outputs": [],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb9hL7Ei3f8P"
      },
      "outputs": [],
      "source": [
        "# crobed image size\n",
        "batch_size = 16\n",
        "img_size = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0v8aO_TuHv_I"
      },
      "outputs": [],
      "source": [
        "tr_gen = ImageDataGenerator()\n",
        "ts_gen = ImageDataGenerator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TD3bNY631Au"
      },
      "outputs": [],
      "source": [
        "train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',color_mode= 'rgb', shuffle= True, batch_size= batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK8XbkTi4DgM"
      },
      "outputs": [],
      "source": [
        "valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',color_mode= 'rgb', shuffle= True, batch_size= batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Hfjy8Ta4G_x"
      },
      "outputs": [],
      "source": [
        "test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',color_mode= 'rgb', shuffle= False, batch_size= batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atFrNyqy4Puh"
      },
      "outputs": [],
      "source": [
        "g_dict = train_gen.class_indices      # defines dictionary {'class': index}\n",
        "classes = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\n",
        "images, labels = next(train_gen)      # get a batch size samples from the generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhw5p3WM4SAY"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize= (20, 20))\n",
        "\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    image = images[i] / 255       # scales data to range (0 - 255)\n",
        "    plt.imshow(image)\n",
        "    index = np.argmax(labels[i])  # get image index\n",
        "    class_name = classes[index]   # get class of image\n",
        "    plt.title(class_name, color= 'blue', fontsize= 12)\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOg1Jnu9P8EU"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels * BasicBlock.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0N1x3aLMUEmg"
      },
      "outputs": [],
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=1000):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0U_0nixUHli"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTbSG0dCUKN6"
      },
      "outputs": [],
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35P7kNf7UMaY"
      },
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "train_dataset = ImageFolder(root='/content/drive/MyDrive/brain tumor data/Training/', transform=transform)\n",
        "valid_dataset = ImageFolder(root='/content/drive/MyDrive/brain tumor data/Testing/', transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMuvizGGUWlh"
      },
      "outputs": [],
      "source": [
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3n7bZyDwUc70"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "model = ResNet18(BasicBlock, [2, 2, 2, 2], num_classes=len(train_dataset.classes)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1VJ8t1_UfSm"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKoGaUPfUhpO"
      },
      "outputs": [],
      "source": [
        "# Training function with plotting\n",
        "def train_and_save_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs=15, model_path='best_model.pth'):\n",
        "    best_valid_acc = 0.0\n",
        "    training_losses = []\n",
        "    training_accuracies = []\n",
        "    validation_losses = []\n",
        "    validation_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "        train_accuracy = correct_train / total_train\n",
        "        training_losses.append(train_loss / len(train_loader))\n",
        "        training_accuracies.append(train_accuracy)\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss = 0.0\n",
        "        correct_valid = 0\n",
        "        total_valid = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in valid_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                valid_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total_valid += labels.size(0)\n",
        "                correct_valid += (predicted == labels).sum().item()\n",
        "        valid_accuracy = correct_valid / total_valid\n",
        "        validation_losses.append(valid_loss / len(valid_loader))\n",
        "        validation_accuracies.append(valid_accuracy)\n",
        "\n",
        "        if valid_accuracy > best_valid_acc:\n",
        "            best_valid_acc = valid_accuracy\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss / len(train_loader):.4f}, Training Acc: {train_accuracy:.4f}, Valid Loss: {valid_loss / len(valid_loader):.4f}, Valid Acc: {valid_accuracy:.4f}')\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(training_losses, label='Training Loss')\n",
        "    plt.plot(validation_losses, label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(training_accuracies, label='Training Accuracy')\n",
        "    plt.plot(validation_accuracies, label='Validation Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGzsnBVUUqJ5",
        "outputId": "d59466db-984c-495c-80ed-9cb1c8e441f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15, Training Loss: 0.8345, Training Acc: 0.6705, Valid Loss: 0.6924, Valid Acc: 0.7246\n",
            "Epoch 2/15, Training Loss: 0.5945, Training Acc: 0.7687, Valid Loss: 0.4983, Valid Acc: 0.7933\n",
            "Epoch 3/15, Training Loss: 0.4860, Training Acc: 0.8153, Valid Loss: 0.9079, Valid Acc: 0.6796\n",
            "Epoch 4/15, Training Loss: 0.3751, Training Acc: 0.8618, Valid Loss: 0.5303, Valid Acc: 0.7971\n",
            "Epoch 5/15, Training Loss: 0.3164, Training Acc: 0.8800, Valid Loss: 0.2976, Valid Acc: 0.8810\n",
            "Epoch 6/15, Training Loss: 0.2587, Training Acc: 0.9076, Valid Loss: 0.3575, Valid Acc: 0.8764\n",
            "Epoch 7/15, Training Loss: 0.2123, Training Acc: 0.9199, Valid Loss: 0.2462, Valid Acc: 0.9214\n",
            "Epoch 8/15, Training Loss: 0.1725, Training Acc: 0.9355, Valid Loss: 0.3346, Valid Acc: 0.8879\n",
            "Epoch 9/15, Training Loss: 0.1413, Training Acc: 0.9516, Valid Loss: 0.6378, Valid Acc: 0.7963\n"
          ]
        }
      ],
      "source": [
        "train_and_save_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs=15, model_path='best_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SpKcA79Uk_L"
      },
      "outputs": [],
      "source": [
        "# Function to load a model\n",
        "def load_model(model_path='best_model.pth'):\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=len(train_dataset.classes))\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1o8LSDMUwNV"
      },
      "outputs": [],
      "source": [
        "# Function for prediction\n",
        "def predict_image(model, image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "    image = image.to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "    return predicted.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of2mb7LwUyet"
      },
      "outputs": [],
      "source": [
        "# Example prediction\n",
        "model = load_model('best_model.pth')\n",
        "image_path = '/content/drive/MyDrive/brain tumor data/Testing/glioma/Te-glTr_0000.jpg'  # Update this path\n",
        "predicted_class = predict_image(model, image_path)\n",
        "print(f'Predicted class: {train_dataset.classes[predicted_class]}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PB9nGzaVsHGQKkE1OrlMBaDfw9EFOmmJ",
      "authorship_tag": "ABX9TyPivBlou/GDv5NAyqK8lK8O",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}